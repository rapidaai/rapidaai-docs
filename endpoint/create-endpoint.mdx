---
title: "Create endpoint"
description: "Endpoints allow you to integrate Large Language Models (LLMs) into your application, providing a powerful interface for AI-driven functionalities."
---

## Prerequisites

Before creating an endpoint, ensure that you have integrated the desired AI provider with Rapida. To set up integrations:

1. Navigate to the Integrations section in your Rapida dashboard.
2. Select the AI provider you want to integrate (e.g., OpenAI, Anthropic, Google AI).
3. Follow the provider-specific instructions to complete the integration.

For detailed instructions on setting up integrations, refer to the provider-specific documentation in the Integrations section:

- [OpenAI](/integrations/openai)
- [Anthropic](/integrations/anthropic)
- [Google AI](/integrations/google-ai)
- [Cohere](/integrations/cohere)
- [Azure OpenAI](/integrations/azure-openai)

<Steps>
  <Step title="Choose Model">
    Select the LLM Provider you want to use for your endpoint. The interface shows various options.

    <Note>
      Each model may have different capabilities and pricing structures, so choose
      the one that best fits your needs.
    </Note>

    ![Choose Model Interface](/images/endpoint/choose-model-image.png)

  </Step>

{" "}
<Step title="Select Provider Credential">
  Choose the appropriate credential for the selected provider from the dropdown
  menu. If you haven't set up credentials for this provider yet, you can: -
  Click the "+" button to add a new credential - Click the refresh button to
  update the list of available credentials
  <Note>
    Make sure you've already configured credentials for your chosen provider in
    the Integrations section.
  </Note>
</Step>

  <Step title="Configure Model Settings">
    Depending on the chosen provider, configure various settings such as Frequency Penalty, Temperature, Top P, Max Completion Tokens, Response Format, and Stop Sequences by clicking on the settings icon next to the selected model.

    ![Configure Model Settings](/images/endpoint/configure-settings-image.png)

  </Step>

  <Step title="Set Up Instructions">
    Create a system message and user message template. Define the role or context for the AI, set up the structure for user inputs, and define custom arguments that can be dynamically inserted into your prompts.

    ![Set Up Instructions](/images/endpoint/setup-instructions-image.png)

  </Step>

  <Step title="Define Endpoint Profile">
    Provide a unique name for your endpoint, a brief description of its purpose, and add relevant tags to categorize it.

    ![Define Endpoint Profile](/images/endpoint/define-profile-image.png)

  </Step>
</Steps>

### Additional Notes

- New versions of the assistant will not be deployed automatically. Manual deployment is required to update the production version.
- You can add multiple messages to create more complex conversation flows.
- The interface allows for easy editing and rearranging of messages.

## Finalizing Your Endpoint

After configuring all settings, click the "Create endpoint" or "Configure instruction" button to finalize your endpoint creation. Your new endpoint will then be listed in the Hosted Endpoints dashboard, where you can monitor its status, run count, error rate, and other performance metrics.

By following these steps, you can create a custom endpoint that leverages powerful LLMs to enhance your application's capabilities.
